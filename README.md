# BLAB iOS App ğŸ«§

**Breath â†’ Sound â†’ Light â†’ Consciousness**

[![Swift](https://img.shields.io/badge/Swift-5.9+-orange.svg)](https://swift.org)
[![iOS](https://img.shields.io/badge/iOS-15.0+-blue.svg)](https://developer.apple.com/ios/)
[![License](https://img.shields.io/badge/License-Proprietary-red.svg)](LICENSE)

> Bio-reactive music creation and performance system combining voice, biofeedback, spatial audio, and light control

---

## ğŸš€ Quick Start (Xcode Handoff)

```bash
cd /Users/michpack/blab-ios-app
open Package.swift  # Opens in Xcode automatically
```

Then in Xcode:
- `Cmd+B` to build
- `Cmd+R` to run in simulator
- `Cmd+U` to run tests

**ğŸ“– For detailed handoff guide:** See **[XCODE_HANDOFF.md](XCODE_HANDOFF.md)**

---

## ğŸ“Š Project Status

**Current Phase:** Phase 3 Complete + NDI Integration âœ…
**Last Update:** 2025-11-03
**GitHub:** `vibrationalforce/blab-ios-app`
**Latest Commits:**
- `bd6fd85` - User-friendly NDI optimizations
- `ae03279` - NDI Audio Output
- `65a260f` - API integration complete

### Phase Completion:
- âœ… **Phase 0:** Project Setup & CI/CD (100%)
- âœ… **Phase 1:** Audio Engine Enhancement (85%)
- âœ… **Phase 2:** Visual Engine Upgrade (90%)
- âœ… **Phase 3:** Spatial Audio + Visual + LED (100% âš¡)
- âœ… **Phase 3.5:** NDI Network Audio Streaming (100% ğŸ†•)
- â³ **Phase 4:** Recording & Session System (80%)
- ğŸ”µ **Phase 5:** AI Composition Layer (0%)

**Overall MVP Progress:** ~80%

---

## ğŸ¯ What is BLAB?

BLAB is an **embodied multimodal music system** that transforms biometric signals (HRV, heart rate, breathing), voice, gestures, and facial expressions into:
- ğŸŒŠ **Spatial Audio** (3D/4D/Fibonacci Field Arrays)
- ğŸ¨ **Real-time Visuals** (Cymatics, Mandalas, Particles)
- ğŸ’¡ **LED/DMX Lighting** (Push 3, Art-Net)
- ğŸ¹ **MIDI 2.0 + MPE** output

### Core Features (Implemented):

#### **Audio System:**
- âœ… Real-time voice processing (AVAudioEngine)
- âœ… FFT frequency detection
- âœ… YIN pitch detection
- âœ… Binaural beat generator (8 brainwave states)
- âœ… Node-based audio graph
- âœ… Multi-track recording

#### **Spatial Audio (Phase 3):**
- âœ… 6 spatial modes: Stereo, 3D, 4D Orbital, AFA, Binaural, Ambisonics
- âœ… Fibonacci sphere distribution
- âœ… Head tracking (CMMotionManager @ 60 Hz)
- âœ… iOS 15+ compatible, iOS 19+ optimized

#### **Visual Engine:**
- âœ… 5 visualization modes: Cymatics, Mandala, Waveform, Spectral, Particles
- âœ… Metal-accelerated rendering
- âœ… Bio-reactive colors (HRV â†’ hue)
- âœ… MIDI/MPE parameter mapping

#### **LED/Lighting Control (Phase 3):**
- âœ… Ableton Push 3 (8x8 RGB LED grid, SysEx)
- âœ… DMX/Art-Net (512 channels, UDP)
- âœ… Addressable LED strips (WS2812, RGBW)
- âœ… 7 LED patterns + 6 light scenes
- âœ… Bio-reactive control (HRV â†’ LED colors)

#### **NDI Audio Streaming (Phase 3.5) ğŸ†•:**
- âœ… Network audio streaming (NDI protocol)
- âœ… Ultra-low latency (< 5ms on local network)
- âœ… Auto-device discovery (mDNS/Bonjour)
- âœ… Smart configuration (device + network detection)
- âœ… Auto-recovery (self-healing on network issues)
- âœ… Real-time network monitoring & health scoring
- âœ… Quality adaptation (automatic + manual)
- âœ… Biometric metadata embedding (HRV, HR)
- âœ… One-tap setup wizard (user-friendly)
- âœ… Multiple quality presets (Minimal â†’ Maximum)
- âœ… **Use Cases:**
  - Stream to DAWs (Ableton, Logic, Reaper)
  - Stream to OBS/vMix (broadcasting)
  - Remote collaboration (low-latency)
  - Zero hardware required (WiFi/Ethernet)

#### **Biofeedback:**
- âœ… HealthKit integration (HRV, Heart Rate)
- âœ… HeartMath coherence algorithm
- âœ… Bio-parameter mapping (HRV â†’ audio/visual/light)
- âœ… Real-time signal smoothing

#### **Input Modalities:**
- âœ… Voice (microphone + pitch detection)
- âœ… Face tracking (ARKit, 52 blend shapes)
- âœ… Hand gestures (Vision framework)
- âœ… Biometrics (HealthKit)
- âœ… MIDI input

#### **Unified Control System:**
- âœ… 60 Hz control loop
- âœ… Multi-modal sensor fusion
- âœ… Priority-based input resolution
- âœ… Real-time parameter mapping

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           UnifiedControlHub (60 Hz Loop)                â”‚
â”‚                                                         â”‚
â”‚  Bio â†’ Gesture â†’ Face â†’ Voice â†’ MIDI 2.0 + MPE        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚               â”‚                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚   Spatial   â”‚  â”‚ Visuals  â”‚   â”‚  Lighting  â”‚
    â”‚   Audio     â”‚  â”‚ Mapper   â”‚   â”‚ Controller â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚               â”‚                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ 3D/4D/AFA   â”‚  â”‚ Cymatics â”‚   â”‚  Push 3    â”‚
    â”‚ Fibonacci   â”‚  â”‚ Mandala  â”‚   â”‚  8x8 LEDs  â”‚
    â”‚ Binaural    â”‚  â”‚ Particlesâ”‚   â”‚            â”‚
    â”‚ Ambisonics  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ DMX/Art-Netâ”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components:

1. **UnifiedControlHub** - Central orchestrator (60 Hz control loop)
2. **SpatialAudioEngine** - 3D/4D spatial audio rendering
3. **MIDIToVisualMapper** - MIDI/MPE â†’ visual parameter mapping
4. **Push3LEDController** - Ableton Push 3 LED control
5. **MIDIToLightMapper** - DMX/Art-Net lighting control
6. **MIDI2Manager** - MIDI 2.0 protocol implementation
7. **MPEZoneManager** - MPE (MIDI Polyphonic Expression)

---

## ğŸ“ Project Structure

```
blab-ios-app/
â”œâ”€â”€ Package.swift                    # Swift Package config
â”œâ”€â”€ Sources/Blab/
â”‚   â”œâ”€â”€ BlabApp.swift               # App entry point
â”‚   â”œâ”€â”€ ContentView.swift           # Main UI
â”‚   â”œâ”€â”€ Audio/
â”‚   â”‚   â”œâ”€â”€ AudioEngine.swift       # Core audio engine
â”‚   â”‚   â”œâ”€â”€ Effects/               # Audio effects (reverb, filter, etc.)
â”‚   â”‚   â”œâ”€â”€ DSP/                   # DSP (FFT, pitch detection)
â”‚   â”‚   â””â”€â”€ Nodes/                 # Modular audio nodes
â”‚   â”œâ”€â”€ Spatial/
â”‚   â”‚   â”œâ”€â”€ SpatialAudioEngine.swift     # 3D/4D spatial audio âœ¨
â”‚   â”‚   â”œâ”€â”€ ARFaceTrackingManager.swift  # Face tracking
â”‚   â”‚   â””â”€â”€ HandTrackingManager.swift    # Hand tracking
â”‚   â”œâ”€â”€ Visual/
â”‚   â”‚   â”œâ”€â”€ MIDIToVisualMapper.swift     # MIDI â†’ Visual âœ¨
â”‚   â”‚   â”œâ”€â”€ CymaticsRenderer.swift       # Cymatics patterns
â”‚   â”‚   â”œâ”€â”€ Modes/                       # 5 visualization modes
â”‚   â”‚   â””â”€â”€ Shaders/                     # Metal shaders
â”‚   â”œâ”€â”€ LED/
â”‚   â”‚   â”œâ”€â”€ Push3LEDController.swift     # Push 3 LED âœ¨
â”‚   â”‚   â””â”€â”€ MIDIToLightMapper.swift      # DMX/Art-Net âœ¨
â”‚   â”œâ”€â”€ MIDI/
â”‚   â”‚   â”œâ”€â”€ MIDI2Manager.swift           # MIDI 2.0
â”‚   â”‚   â”œâ”€â”€ MPEZoneManager.swift         # MPE
â”‚   â”‚   â””â”€â”€ MIDIToSpatialMapper.swift    # MIDI â†’ Spatial
â”‚   â”œâ”€â”€ Unified/
â”‚   â”‚   â””â”€â”€ UnifiedControlHub.swift      # Central control âœ¨
â”‚   â”œâ”€â”€ Biofeedback/
â”‚   â”‚   â”œâ”€â”€ HealthKitManager.swift       # HealthKit
â”‚   â”‚   â””â”€â”€ BioParameterMapper.swift     # Bio â†’ Audio mapping
â”‚   â”œâ”€â”€ Recording/                       # Multi-track recording
â”‚   â”œâ”€â”€ Views/                           # UI components
â”‚   â””â”€â”€ Utils/                           # Utilities
â”œâ”€â”€ Tests/BlabTests/                     # Unit tests
â””â”€â”€ Docs/                                # Documentation

âœ¨ = Phase 3 components (2228 lines optimized code)
```

---

## ğŸ› ï¸ Technical Stack

- **Language:** Swift 5.9+
- **UI:** SwiftUI + Combine
- **Audio:** AVFoundation + CoreAudio
- **Graphics:** Metal + SwiftUI Canvas
- **Biofeedback:** HealthKit + CoreMotion
- **Spatial:** AVAudioEnvironmentNode (iOS 19+)
- **Vision:** ARKit + Vision Framework
- **MIDI:** CoreMIDI + MIDI 2.0
- **Networking:** Network Framework (UDP/Art-Net)
- **Platform:** iOS 15.0+ (optimized for iOS 19+)

---

## ğŸ§ª Testing

### Run Tests:
```bash
swift test
# or in Xcode: Cmd+U
```

### Test Coverage:
- **Current:** ~40%
- **Target:** >80%

### Test Suites:
- Audio Engine Tests
- Biofeedback Tests
- Pitch Detection Tests
- Phase 3 Integration Tests (recommended to add)

---

## ğŸ“– Documentation

### Quick References:
- **[XCODE_HANDOFF.md](XCODE_HANDOFF.md)** - Xcode development guide (MUST READ)
- **[NDI_AUDIO_SETUP.md](NDI_AUDIO_SETUP.md)** ğŸ†• - NDI Audio Streaming guide (complete)
- **[SYSTEM_ANALYSIS.md](SYSTEM_ANALYSIS.md)** ğŸ†• - Complete system analysis & roadmap
- **[PHASE_3_OPTIMIZED.md](PHASE_3_OPTIMIZED.md)** - Phase 3 optimization details
- **[DAW_INTEGRATION_GUIDE.md](DAW_INTEGRATION_GUIDE.md)** - DAW integration
- **[BLAB_IMPLEMENTATION_ROADMAP.md](BLAB_IMPLEMENTATION_ROADMAP.md)** - Full roadmap
- **[BLAB_90_DAY_ROADMAP.md](BLAB_90_DAY_ROADMAP.md)** - 90-day plan

### Additional Docs:
- `COMPATIBILITY.md` - iOS compatibility notes
- `DEPLOYMENT.md` - Deployment guide
- `TESTFLIGHT_SETUP.md` - TestFlight configuration

---

## ğŸ¨ UI Development

### Recommended Next Steps:

1. **Create Phase 3 Controls:**
   - See `XCODE_HANDOFF.md` Section 4.1 for full code
   - Add spatial audio mode selector
   - Add visual mapping controls
   - Add Push 3 LED pattern picker
   - Add DMX scene selector

2. **Integrate into ContentView:**
   - Add settings/gear button
   - Show Phase3ControlsView in sheet
   - Wire UnifiedControlHub to UI

3. **Add Real-time Displays:**
   - Control loop frequency indicator
   - Bio-signal displays (HRV, HR)
   - Spatial audio source visualization
   - LED pattern preview

---

## âš™ï¸ Configuration

### Info.plist Requirements:
```xml
<!-- Microphone -->
<key>NSMicrophoneUsageDescription</key>
<string>BLAB needs microphone access to process your voice</string>

<!-- Health Data -->
<key>NSHealthShareUsageDescription</key>
<string>BLAB needs access to heart rate data for bio-reactive music</string>

<!-- Camera (for face tracking) -->
<key>NSCameraUsageDescription</key>
<string>BLAB uses face tracking for expressive control</string>
```

### Network Configuration (DMX/Art-Net):
```swift
// Default Art-Net settings
Address: 192.168.1.100
Port: 6454
Universe: 512 channels
```

---

## ğŸš€ Deployment

### Build for TestFlight:
```bash
# 1. Archive in Xcode
Product â†’ Archive

# 2. Upload to App Store Connect
Window â†’ Organizer â†’ Distribute App

# 3. TestFlight
Invite testers via App Store Connect
```

See `TESTFLIGHT_SETUP.md` for detailed instructions.

---

## ğŸ› Known Issues & Limitations

### Expected Behaviors:
1. **Simulator:**
   - HealthKit not available â†’ Use mock data
   - Push 3 not detected â†’ Hardware required
   - Head tracking disabled â†’ No motion sensors

2. **Hardware Requirements:**
   - Push 3: USB connection required
   - DMX: Network 192.168.1.100 must be reachable
   - AirPods Pro: For head tracking (iOS 19+)

3. **iOS Versions:**
   - iOS 15-18: Full functionality except iOS 19+ features
   - iOS 19+: AVAudioEnvironmentNode for spatial audio

### TODOs (non-critical):
```swift
// UnifiedControlHub: Calculate breathing rate from HRV
// UnifiedControlHub: Get audio level from audio engine
```

These use fallback values that work fine.

---

## ğŸ“Š Code Quality Metrics

### Phase 3 + NDI Statistics:
- **Phase 3 Lines:** 2,228 (optimized)
- **NDI Lines:** 5,144 (12 new files)
- **Total Code:** ~21,944 lines (67 Swift files)
- **Force Unwraps:** 0 âœ…
- **Compiler Warnings:** 0 âœ…
- **Test Coverage:** ~40% (target: >80%)
- **Documentation:** Comprehensive âœ…
  - NDI_AUDIO_SETUP.md (800+ lines)
  - SYSTEM_ANALYSIS.md (comprehensive)

### Performance:
- **Control Loop:** 60 Hz target âœ…
- **CPU Usage:** <30% target
- **Memory:** <200 MB target
- **Frame Rate:** 60 FPS (target 120 FPS on ProMotion)

---

## ğŸ¤ Development Workflow

### Git Workflow:
```bash
# Check status
git status
git log --oneline -5

# Create feature branch
git checkout -b feature/my-feature

# Commit changes
git add .
git commit -m "feat: Add feature description"

# Push to GitHub
git push origin feature/my-feature

# Create PR on GitHub
```

### Commit Convention:
- `feat:` New feature
- `fix:` Bug fix
- `docs:` Documentation
- `refactor:` Code refactoring
- `test:` Tests
- `chore:` Maintenance

---

## ğŸ“ Support

### Issues & Questions:
- Open GitHub issue
- Check documentation in `/Docs`
- Review `XCODE_HANDOFF.md`

### Development Team:
- **Original Implementation:** ChatGPT Codex
- **Lead Developer & Optimization:** Claude Code
- **Project Owner:** vibrationalforce

---

## ğŸ¯ Roadmap Summary

### âœ… Completed:
- Phase 0: Project Setup
- Phase 1: Audio Engine (85%)
- Phase 2: Visual Engine (90%)
- **Phase 3: Spatial + Visual + LED (100%)** âš¡

### â³ In Progress:
- Phase 4: Recording & Session System (80%)

### ğŸ”µ Planned:
- Phase 5: AI Composition Layer
- Phase 6: Networking & Collaboration
- Phase 7: AUv3 Plugin + MPE
- Phase 8: Vision Pro / ARKit
- Phase 9: Distribution & Publishing
- Phase 10: Polish & Release

**Estimated MVP Completion:** 3-4 months
**Full Feature Set:** 6-7 months

See `BLAB_IMPLEMENTATION_ROADMAP.md` for details.

---

## ğŸ“œ License

Copyright Â© 2025 BLAB Studio. All rights reserved.

Proprietary software - not for redistribution.

---

## ğŸ«§ Philosophy

> "BLAB is not just a music app - it's an interface to embodied consciousness.
> Through breath, biometrics, and intention, we transform life itself into art."

**breath â†’ sound â†’ light â†’ consciousness**

---

**Built with** â¤ï¸ using Swift, SwiftUI, AVFoundation, Metal, HealthKit, ARKit, and pure creative energy.

**Status:** âœ… Ready for Xcode Development
**Next:** ğŸš€ UI Integration & Testing
**Vision:** ğŸŒŠ Embodied Multimodal Music System

ğŸ«§ *Let's flow...* âœ¨
